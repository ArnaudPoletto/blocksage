
ðŸš€ Training AutoEncoderTrainer method for 1 epochs...
Epochs:   0%|                                                                                                                                                                                                                                                   | 0/1 [00:00<?, ?epoch/s]

Epochs:   0%|                                                                                                                                                                                                  | 0/1 [00:03<?, ?epoch/s, batch=1/276, train_loss=0.0000, val_loss=0.0000]
tensor(0.0066, device='cuda:0', grad_fn=<DivBackward1>)
tensor(0.0034, device='cuda:0', grad_fn=<DivBackward1>)


Epochs:   0%|                                                                                                                                                                                                  | 0/1 [00:08<?, ?epoch/s, batch=7/276, train_loss=0.0000, val_loss=0.0000]
tensor(0.0014, device='cuda:0', grad_fn=<DivBackward1>)
tensor(0.0056, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                  | 0/1 [00:10<?, ?epoch/s, batch=9/276, train_loss=0.0000, val_loss=0.0000]
tensor(0.0034, device='cuda:0', grad_fn=<DivBackward1>)
tensor(0.0021, device='cuda:0', grad_fn=<DivBackward1>)
tensor(0.0008, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                                                  | 0/1 [00:11<?, ?epoch/s, eval_batch=1/16]
tensor(0.0065, device='cuda:0')
tensor(0.0028, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                  | 0/1 [00:13<?, ?epoch/s, eval_batch=4/16]
tensor(0.0161, device='cuda:0')
tensor(0.0040, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                  | 0/1 [00:15<?, ?epoch/s, eval_batch=6/16]
tensor(0.0082, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                  | 0/1 [00:17<?, ?epoch/s, eval_batch=9/16]
tensor(0.0996, device='cuda:0')
tensor(0.0150, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                 | 0/1 [00:19<?, ?epoch/s, eval_batch=12/16]
tensor(0.0495, device='cuda:0')
tensor(0.0032, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                 | 0/1 [00:21<?, ?epoch/s, eval_batch=14/16]
tensor(0.0023, device='cuda:0')
ðŸŽ‰ Saving model with new best loss: 0.0162

Epochs:   0%|                                                                                                                                                                                                 | 0/1 [00:23<?, ?epoch/s, batch=11/276, train_loss=0.0037, val_loss=0.0162]
tensor(0.0016, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                 | 0/1 [00:25<?, ?epoch/s, batch=13/276, train_loss=0.0037, val_loss=0.0162]
tensor(0.0009, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                 | 0/1 [00:27<?, ?epoch/s, batch=15/276, train_loss=0.0037, val_loss=0.0162]
tensor(0.0052, device='cuda:0', grad_fn=<DivBackward1>)
tensor(0.0038, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                 | 0/1 [00:29<?, ?epoch/s, batch=17/276, train_loss=0.0037, val_loss=0.0162]
tensor(0.0214, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                 | 0/1 [00:31<?, ?epoch/s, batch=20/276, train_loss=0.0037, val_loss=0.0162]
tensor(0.0054, device='cuda:0')
tensor(0.0068, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                  | 0/1 [00:33<?, ?epoch/s, eval_batch=3/16]
tensor(0.0041, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                  | 0/1 [00:35<?, ?epoch/s, eval_batch=5/16]
tensor(0.0043, device='cuda:0')
tensor(0.0019, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                  | 0/1 [00:37<?, ?epoch/s, eval_batch=8/16]
tensor(0.0369, device='cuda:0')
tensor(0.0990, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                 | 0/1 [00:39<?, ?epoch/s, eval_batch=11/16]
tensor(0.0029, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                 | 0/1 [00:41<?, ?epoch/s, eval_batch=13/16]
tensor(0.0034, device='cuda:0')
tensor(0.0017, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                           | 0/1 [00:43<?, ?epoch/s, train_batch=20/276, train_loss=0.0140, val_loss=0.0163]
tensor(0.0027, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                 | 0/1 [00:46<?, ?epoch/s, batch=23/276, train_loss=0.0140, val_loss=0.0163]
tensor(0.0035, device='cuda:0', grad_fn=<DivBackward1>)
tensor(0.0040, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                 | 0/1 [00:47<?, ?epoch/s, batch=25/276, train_loss=0.0140, val_loss=0.0163]
tensor(0.0028, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                 | 0/1 [00:49<?, ?epoch/s, batch=27/276, train_loss=0.0140, val_loss=0.0163]
tensor(0.0017, device='cuda:0', grad_fn=<DivBackward1>)
tensor(0.0056, device='cuda:0', grad_fn=<DivBackward1>)

Epochs:   0%|                                                                                                                                                                                                 | 0/1 [00:52<?, ?epoch/s, batch=30/276, train_loss=0.0140, val_loss=0.0163]
tensor(0.0046, device='cuda:0')

Epochs:   0%|                                                                                                                                                                                                                                  | 0/1 [00:53<?, ?epoch/s, eval_batch=2/16]
Epochs:   0%|                                                                                                                                                                                                                                  | 0/1 [00:55<?, ?epoch/s, eval_batch=3/16]
Traceback (most recent call last):
  File "C:\Users\arnau\Desktop\blocksage\git\blocksage\src\autoencoder\autoencoder_train.py", line 156, in <module>
    statistics = trainer.train(
                 ^^^^^^^^^^^^^^
  File "C:\Users\arnau\Desktop\blocksage\git\blocksage\src\autoencoder\..\..\src\trainers\trainer.py", line 162, in train
    self._train_one_epoch(
  File "C:\Users\arnau\Desktop\blocksage\git\blocksage\src\autoencoder\..\..\src\trainers\trainer.py", line 325, in _train_one_epoch
    stats = self._evaluate(val_loader, bar=bar)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\Desktop\blocksage\git\blocksage\src\autoencoder\..\..\src\trainers\trainer.py", line 386, in _evaluate
    for batch_idx, batch in enumerate(loader):
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\utils\data\dataloader.py", line 631, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\utils\data\dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 54, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\utils\data\_utils\collate.py", line 277, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\utils\data\_utils\collate.py", line 144, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\utils\data\_utils\collate.py", line 121, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\utils\data\_utils\collate.py", line 174, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt