
Epochs:   0%|                                                                                                                                                                                                                                                                               | 0/1 [00:00<?, ?epoch/s]









































Epochs:   0%|                                                                                                                                                                                                                           | 0/1 [01:28<?, ?epoch/s, batch=46/27638, train_loss=0.0000, val_loss=0.0000]
Traceback (most recent call last):
  File "C:\Users\arnau\Desktop\blocksage\git\blocksage\src\autoencoder\autoencoder_train.py", line 146, in <module>
    statistics = trainer.train(
                 ^^^^^^^^^^^^^^
  File "C:\Users\arnau\Desktop\blocksage\git\blocksage\src\autoencoder\..\..\src\trainers\trainer.py", line 162, in train
    self._train_one_epoch(
  File "C:\Users\arnau\Desktop\blocksage\git\blocksage\src\autoencoder\..\..\src\trainers\trainer.py", line 303, in _train_one_epoch
    scaler.step(optimizer)
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\cuda\amp\grad_scaler.py", line 452, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\cuda\amp\grad_scaler.py", line 349, in _maybe_opt_step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\arnau\anaconda3\envs\dm\Lib\site-packages\torch\cuda\amp\grad_scaler.py", line 349, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
               ^^^^^^^^
KeyboardInterrupt